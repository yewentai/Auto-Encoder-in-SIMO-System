{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from torch.optim import SGD, Adam\n",
    "from tqdm import tqdm\n",
    "from utils import Encoder, Decoder\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 16 # number of constellation points\n",
    "flag_train_model = True # True: train model, False: load pre-trained model\n",
    "Path = \"./models/ae_miso_rayleigh_16qam.pth\"\n",
    "encoder = Encoder([M, 64, 64, 64, 8]).to(device)\n",
    "decoder = Decoder([8, 512, 512, 512, M]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not flag_train_model:\n",
    "    # read model if exists else train model\n",
    "    checkpoint = torch.load(Path, map_location=torch.device('cpu'))\n",
    "    encoder.load_state_dict(checkpoint[\"Encoder\"])\n",
    "    decoder.load_state_dict(checkpoint[\"Decoder\"])\n",
    "    print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag_train_model:\n",
    "    train_snr = 15 # training SNR in dB\n",
    "    criterion = nn.NLLLoss()     # negative log likelihood loss\n",
    "    para = list(encoder.parameters()) + list(decoder.parameters())  # get all parameters\n",
    "    opt = SGD(para, lr=0.1)\n",
    "    loss = []  # store the loss value\n",
    "    totEpoch = int(1e4)  # total number of epochs\n",
    "    iteration = tqdm(range(totEpoch), desc=\"loss\")\n",
    "\n",
    "    for iterator in iteration:\n",
    "        iteration.set_description(\"epoch={:}\".format(iterator))\n",
    "        messages = torch.randint(0, M, size=(51200,), device=device)  # generate \n",
    "        one_hot = F.one_hot(messages, M).float()  # convert to one hot encoding shape=(16000, M)\n",
    "        tx =encoder(one_hot)\n",
    "\n",
    "        tx_real = tx[:, np.arange(0,4)].view(-1,2,2)\n",
    "        tx_imag = tx[:, np.arange(4,8)].view(-1,2,2)\n",
    "        ch_real = torch.randn((messages.shape[0], 1, 2)) / torch.sqrt(torch.tensor(2.0)).to(device)\n",
    "        ch_imag = torch.randn((messages.shape[0], 1, 2)) / torch.sqrt(torch.tensor(2.0)).to(device)\n",
    "        rx_real = torch.bmm(ch_real, tx_real) - torch.bmm(ch_imag, tx_imag)\n",
    "        rx_imag = torch.bmm(ch_imag, tx_real) + torch.bmm(ch_real, tx_imag)\n",
    "\n",
    "        rx = torch.cat([rx_real, rx_imag], axis=-2).view(-1,4)\n",
    "\n",
    "        sigma = np.sqrt(0.5/(np.power(10, train_snr/10)))\n",
    "        noise = (sigma * torch.randn(rx.shape)).to(device)\n",
    "        rx = rx + noise\n",
    "\n",
    "        csi = torch.cat([ch_real, ch_imag], axis=-2).view(-1,4)\n",
    "\n",
    "        y_pred = decoder(torch.cat([rx, csi], axis=-1))\n",
    "\n",
    "        cross_entropy = criterion(y_pred, messages)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        cross_entropy.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        loss.append(cross_entropy.item())\n",
    "\n",
    "\n",
    "    # plot the loss\n",
    "    plt.figure()\n",
    "    plt.plot(loss)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "    # save the model\n",
    "    torch.save({\n",
    "            'Encoder': encoder.state_dict(),\n",
    "            'Decoder': decoder.state_dict(),\n",
    "            }, Path)\n",
    "    print(\"Model saved\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte-Carlo simulation for SER\n",
    "SER = np.array([])\n",
    "SNR_arr = np.arange(0, 23, 2)\n",
    "iteration = tqdm(range(len(SNR_arr)), desc=\"loss\")\n",
    "for iterator in iteration:\n",
    "    test_snr = SNR_arr[iterator]\n",
    "    iteration.set_description(\"SNR={:.1f}dB\".format(test_snr))\n",
    "    totErr = 0\n",
    "    totSym = 0\n",
    "    minErr = 1e3\n",
    "    maxSym = minErr * 1e4\n",
    "    minSym = minErr * 1e2\n",
    "    while totErr < minErr and totSym < maxSym or totSym < minSym:\n",
    "        batch = 40\n",
    "        messages = np.arange(M) # 0, 1, 2,..., M-1\n",
    "        messages = np.tile(messages, batch) # 0, 1, 2,..., M-1, 0, 1, 2,..., M-1, ...\n",
    "        test_labels = to_categorical(messages) # one-hot encoding\n",
    "\n",
    "        ch_real = (torch.randn((M * batch, 1, 2)) / np.sqrt(2)).to(device)\n",
    "        ch_imag = (torch.randn((M * batch, 1, 2)) / np.sqrt(2)).to(device)\n",
    "\n",
    "        test_data = torch.from_numpy(test_labels).to(device)\n",
    "        test_label = torch.from_numpy(messages).to(device)\n",
    "\n",
    "        tx = encoder(test_data)\n",
    "        tx_real = tx[:, np.arange(0, 4)].view(-1, 2, 2)\n",
    "        tx_imag = tx[:, np.arange(4, 8)].view(-1, 2, 2)\n",
    "\n",
    "        rx_real = torch.bmm(ch_real, tx_real) - torch.bmm(ch_imag, tx_imag)\n",
    "        rx_imag = torch.bmm(ch_imag, tx_real) + torch.bmm(ch_real, tx_imag)\n",
    "\n",
    "        rx = torch.cat([rx_real, rx_imag], axis=-2).view(-1, 4)\n",
    "\n",
    "        sigma = np.sqrt(0.5 / (np.power(10, test_snr / 10)))\n",
    "        noise = (sigma * torch.randn(rx.shape)).to(device)\n",
    "        rx = rx + noise\n",
    "\n",
    "        csi = torch.cat([ch_real, ch_imag], axis=-2).view(-1, 4)\n",
    "\n",
    "        rx_csi = torch.cat([rx, csi], axis=-1)\n",
    "        y_pred = decoder(rx_csi)\n",
    "\n",
    "        classification = torch.argmax(y_pred, axis=-1).to(\"cpu\").detach().numpy()\n",
    "\n",
    "        correct = np.equal(classification, messages)\n",
    "\n",
    "        totSym = totSym + correct.shape[0]\n",
    "        totErr = totErr + correct.shape[0] - np.sum(correct)\n",
    "\n",
    "    SER = np.append(SER, totErr / totSym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_2dGS = np.array(\n",
    "    [\n",
    "        0.8582738919,\n",
    "        0.77518119729,\n",
    "        0.6638753775,\n",
    "        0.5241933032,\n",
    "        0.3764218117,\n",
    "        0.2427,\n",
    "        0.1367,\n",
    "        0.07344675006,\n",
    "        0.03492563936,\n",
    "        0.0158441070,\n",
    "        0.0069469963,\n",
    "        0.0029697814,\n",
    "    ]\n",
    ")\n",
    "\n",
    "baseline_4dGS = np.array(\n",
    "    [\n",
    "        0.8525,\n",
    "        0.7667,\n",
    "        0.6476,\n",
    "        0.5039,\n",
    "        0.3517,\n",
    "        0.2212,\n",
    "        0.1245,\n",
    "        0.06367,\n",
    "        0.02986,\n",
    "        0.01373,\n",
    "        0.005634,\n",
    "        0.002427,\n",
    "    ]\n",
    ")\n",
    "\n",
    "baseline_16qam = np.array(\n",
    "    [\n",
    "        0.863982915109450,\n",
    "        0.789824218750000,\n",
    "        0.683372881355932,\n",
    "        0.553873626373626,\n",
    "        0.394372549019608,\n",
    "        0.258779977466602,\n",
    "        0.153877394636015,\n",
    "        0.082014608979925,\n",
    "        0.039804998762683,\n",
    "        0.018117047197906,\n",
    "        0.008057689702067,\n",
    "        0.003462703794546,\n",
    "    ]\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "# plt.semilogy(np.arange(0,23,2), baseline_QPSK,'-*', label='Alamouti w/ QPSK')\n",
    "\n",
    "plt.semilogy(np.arange(0, 24, 2), baseline_16qam, \"-*\", label=\"alamouti /w 16qam\")\n",
    "plt.semilogy(np.arange(0, 24, 2), baseline_2dGS, \"->\", label=\"alamouti /w 2d-GS \")\n",
    "plt.semilogy(np.arange(0, 24, 2), baseline_4dGS, \"->\", label=\"alamouti /w 4D-GS \")\n",
    "plt.semilogy(np.arange(0, 23, 2), SER, \"-<\", label=\"AE\")\n",
    "\n",
    "# , SNR_array, SER, '-o'\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 400\n",
    "messages = np.arange(M)\n",
    "messages = np.tile(messages, batch)\n",
    "test_labels = to_categorical(messages)\n",
    "\n",
    "ch_real = (torch.randn((M * batch, 2, 1)) / np.sqrt(2)).to(device)\n",
    "ch_imag = (torch.randn((M * batch, 2, 1)) / np.sqrt(2)).to(device)\n",
    "\n",
    "test_data = torch.from_numpy(test_labels).to(device)\n",
    "test_label = torch.from_numpy(messages).to(device)\n",
    "\n",
    "transmitted_signals = encoder(test_data).to(\"cpu\").detach().numpy()\n",
    "\n",
    "s1 = transmitted_signals[:, 0] + 1j * transmitted_signals[:, 4]\n",
    "s2 = transmitted_signals[:, 1] + 1j * transmitted_signals[:, 5]\n",
    "s3 = transmitted_signals[:, 2] + 1j * transmitted_signals[:, 6]\n",
    "s4 = transmitted_signals[:, 3] + 1j * transmitted_signals[:, 7]\n",
    "\n",
    "a = 0  #### rotation angles should be carefully find for every different realization\n",
    "s1 = s1 * np.exp(1j * np.pi * a / 4)\n",
    "s2 = s2 * np.exp(1j * np.pi * a / 4)\n",
    "s3 = s3 * np.exp(1j * np.pi * a / 4)\n",
    "s4 = s4 * np.exp(1j * np.pi * a / 4)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(9, 9))\n",
    "ax1 = axs[0, 0]\n",
    "ax2 = axs[0, 1]\n",
    "ax3 = axs[1, 0]\n",
    "ax4 = axs[1, 1]\n",
    "for axe in [ax1, ax2, ax3, ax4]:\n",
    "    axe.grid(True)\n",
    "    axe.set_xlim([-1.5, 1.5])\n",
    "    axe.set_ylim([-1.5, 1.5])\n",
    "#     axe.set_xlabel('Real')\n",
    "#     axe.set_ylabel('Imaginary')\n",
    "\n",
    "\n",
    "color_map = [\n",
    "    \"r\",\n",
    "    \"b\",\n",
    "    \"g\",\n",
    "    \"r\",\n",
    "    \"c\",\n",
    "    \"m\",\n",
    "    \"y\",\n",
    "    \"k\",\n",
    "    \"w\",\n",
    "    \"r\",\n",
    "    \"b\",\n",
    "    \"g\",\n",
    "    \"r\",\n",
    "    \"c\",\n",
    "    \"m\",\n",
    "    \"y\",\n",
    "    \"k\",\n",
    "    \"w\",\n",
    "]\n",
    "marker_style = [\n",
    "    \"o\",\n",
    "    \"v\",\n",
    "    \"^\",\n",
    "    \"<\",\n",
    "    \">\",\n",
    "    \"8\",\n",
    "    \"s\",\n",
    "    \"p\",\n",
    "    \"*\",\n",
    "    \"h\",\n",
    "    \"H\",\n",
    "    \"D\",\n",
    "    \"d\",\n",
    "    \"P\",\n",
    "    \"X\",\n",
    "    \"o\",\n",
    "]\n",
    "\n",
    "ax1.scatter(s1[0:16].real, s1[0:16].imag, c=\"k\", s=10)\n",
    "ax3.scatter(s2[0:16].real, s2[0:16].imag, c=\"k\", s=10)\n",
    "ax2.scatter(s3[0:16].real, s3[0:16].imag, c=\"k\", s=10)\n",
    "ax4.scatter(s4[0:16].real, s4[0:16].imag, c=\"k\", s=10)\n",
    "for i in np.arange(1, 5):\n",
    "    ax1.scatter(s1[i].real, s1[i].imag, c=color_map[i], s=100, marker=marker_style[i])\n",
    "    ax3.scatter(s2[i].real, s2[i].imag, c=color_map[i], s=100, marker=marker_style[i])\n",
    "    ax2.scatter(s3[i].real, s3[i].imag, c=color_map[i], s=100, marker=marker_style[i])\n",
    "    ax4.scatter(s4[i].real, s4[i].imag, c=color_map[i], s=100, marker=marker_style[i])\n",
    "\n",
    "ax1.set_title(\"Tx sym, Ant 1, T1\")\n",
    "ax2.set_title(\"Tx sym, Ant 2, T1\")\n",
    "ax3.set_title(\"Tx sym, Ant 1, T2\")\n",
    "ax4.set_title(\"Tx sym, Ant 2, T2\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
