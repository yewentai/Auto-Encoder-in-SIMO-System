{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import torch\n",
                "import torch.nn.functional as F\n",
                "from torch import nn\n",
                "from torch.optim import Adam\n",
                "from tqdm import tqdm\n",
                "import os\n",
                "\n",
                "from utils import *"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "CONFIG_TRAIN = {\n",
                "    \"antenna_config\": \"siso\",  # Antenna configuration\n",
                "    \"channel_model\": \"rayleigh\",  # Channel type\n",
                "    \"M\": 16,  # Number of constellation points\n",
                "    \"flag_train_model\": True,  # Flag to control training\n",
                "    \"training_snr\": 12,  # Training SNR (dB)\n",
                "}\n",
                "CONFIG_TRAIN[\"best_encoder_path\"] = (\n",
                "    f\"./model/encoder_{CONFIG_TRAIN['antenna_config']}_{CONFIG_TRAIN['channel_model']}_{CONFIG_TRAIN['M']}qam_best_encoder.pt\"\n",
                ")\n",
                "CONFIG_TRAIN[\"best_decoder_path\"] = (\n",
                "    f\"./model/decoder_{CONFIG_TRAIN['antenna_config']}_{CONFIG_TRAIN['channel_model']}_{CONFIG_TRAIN['M']}qam_best_decoder.pt\"\n",
                ")\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "encoder = Encoder([CONFIG_TRAIN[\"M\"], 16, 16, 2]).to(device)\n",
                "decoder = Decoder([2, 256, 256, CONFIG_TRAIN[\"M\"]]).to(device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "checkpoint = torch.load(CONFIG_TRAIN[\"best_encoder_path\"], map_location=device)\n",
                "encoder.load_state_dict(checkpoint)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def save_decoder(decoder, optimizer, loss):\n",
                "    \"\"\"\n",
                "    Save the model to a file.\n",
                "    - model_state_dict: the model state dictionary\n",
                "    - optimizer_state_dict: the optimizer state dictionary\n",
                "    - loss: the loss history\n",
                "    \"\"\"\n",
                "    torch.save(\n",
                "        {\n",
                "            \"model_state_dict\": decoder.state_dict(),\n",
                "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
                "            \"loss\": loss,\n",
                "        },\n",
                "        CONFIG_TRAIN[\"best_decoder_path\"],\n",
                "    )\n",
                "\n",
                "\n",
                "def save_encoder(encoder, optimizer, loss):\n",
                "    \"\"\"\n",
                "    Save the model to a file.\n",
                "    - model_state_dict: the model state dictionary\n",
                "    - optimizer_state_dict: the optimizer state dictionary\n",
                "    - loss: the loss history\n",
                "    \"\"\"\n",
                "    torch.save(\n",
                "        {\n",
                "            \"model_state_dict\": encoder.state_dict(),\n",
                "            \"optimizer\": optimizer.state_dict(),\n",
                "            \"loss\": loss,\n",
                "        },\n",
                "        CONFIG_TRAIN[\"best_encoder_path\"],\n",
                "    )\n",
                "\n",
                "\n",
                "def train_decoder(\n",
                "    decoder, optimizer, max_iterations, loss_hist, batch_size, messages, rx\n",
                "):\n",
                "    criterion = nn.NLLLoss()  # negative log likelihood loss\n",
                "    best_loss = float(\"inf\")  # Initialize the best loss to infinity\n",
                "    try:\n",
                "        for iterator in tqdm(\n",
                "            range(len(loss_hist), max_iterations), desc=\"training process\"\n",
                "        ):\n",
                "            start_index = int(iterator * batch_size)\n",
                "            end_index = int((iterator + 1) * batch_size - 1)\n",
                "            messages_batch = messages[start_index:end_index]\n",
                "            rx_batch = rx[iterator * batch_size : (iterator + 1) * batch_size - 1]\n",
                "            y_pred = decoder(rx_batch)\n",
                "            loss = criterion(y_pred, messages_batch)\n",
                "            optimizer.zero_grad()\n",
                "            loss.backward()\n",
                "            optimizer.step()\n",
                "            loss_hist.append(loss.item())\n",
                "\n",
                "            if loss.item() < best_loss:\n",
                "                best_loss = loss.item()\n",
                "                save_decoder(decoder, loss_hist, optimizer)\n",
                "\n",
                "        print(\"Training complete\")\n",
                "\n",
                "    except KeyboardInterrupt:\n",
                "        save_decoder(decoder, loss_hist, optimizer)\n",
                "        print(\"Training interrupted\")\n",
                "\n",
                "    save_decoder(decoder, loss_hist, optimizer)\n",
                "    # Plot the loss\n",
                "    plt.semilogy(loss_hist)\n",
                "    plt.xlabel(\"Epoch\")\n",
                "    plt.ylabel(\"Loss\")\n",
                "    plt.title(\"Training Loss\")\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Train or load the model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if CONFIG_TRAIN[\"flag_train_model\"]:\n",
                "    # check if there is a checkpoint to resume training\n",
                "    if os.path.exists(CONFIG_TRAIN[\"best_decoder_path\"]):\n",
                "        checkpoint = torch.load(CONFIG_TRAIN[\"best_decoder_path\"], map_location=device)\n",
                "        # load the model, optimizer a loss history\n",
                "        decoder.load_state_dict(checkpoint[\"Decoder\"])\n",
                "\n",
                "    parameters = list(decoder.parameters())\n",
                "    optimizer = Adam(parameters, lr=0.01)\n",
                "\n",
                "    if os.path.exists(CONFIG_TRAIN[\"best_decoder_path\"]):\n",
                "        # optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
                "        loss_hist = checkpoint[\"loss\"]\n",
                "        print(f\"Resuming training from iterator {len(loss_hist)}\")\n",
                "    else:\n",
                "        loss_hist = []\n",
                "        print(\"Training from scratch\")\n",
                "\n",
                "    max_iterations = int(1e3)  # Total number of epochs to train\n",
                "    batch_size = int(1e4)  # Number of messages to use for training (batch size)\n",
                "    if max_iterations > len(loss_hist):\n",
                "        num_messages = (max_iterations - len(loss_hist)) * batch_size\n",
                "        messages = torch.randint(0, 16, size=(num_messages + 8,), device=device)\n",
                "        one_hot = F.one_hot(messages, 16).float()\n",
                "        tx = encoder(one_hot)\n",
                "        # write tx to a binary file\n",
                "        tx = tx.detach().numpy()\n",
                "        with open(\"./file/tx.dat\", \"wb\") as f:\n",
                "            f.write(tx.tobytes())\n",
                "        # run channel.py to generate rx\n",
                "        os.system(\"python3 ./gnuradio/fading_awgn_model.py\")\n",
                "        # read rx from a binary file\n",
                "        with open(\"./file/rx.dat\", \"rb\") as f:\n",
                "            rx = np.frombuffer(f.read(), dtype=np.float32)\n",
                "        rx = torch.from_numpy(rx).to(device)\n",
                "        rx = rx.view(-1, 2)\n",
                "        messages = messages[3:-5]\n",
                "        train_decoder(\n",
                "            decoder, optimizer, max_iterations, loss_hist, batch_size, messages, rx\n",
                "        )\n",
                "    else:\n",
                "        print(\"epochs already completed\")\n",
                "else:\n",
                "    # check if there is a checkpoint to load the model\n",
                "    if os.path.exists(CONFIG_TRAIN[\"best_decoder_path\"]):\n",
                "        checkpoint = torch.load(CONFIG_TRAIN[\"best_decoder_path\"], map_location=device)\n",
                "        decoder.load_state_dict(checkpoint[\"Decoder\"])\n",
                "        print(\"Model loaded. Training iterator: \", len(checkpoint[\"loss\"]))\n",
                "    else:\n",
                "        print(\n",
                "            \"Model not found, please set flag_train_model to True and train the model\"\n",
                "        )\n",
                "        exit(1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Test the model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "num_messages = int(1e4)\n",
                "messages = torch.randint(0, 16, size=(num_messages + 8,), device=device)\n",
                "one_hot = F.one_hot(messages, 16).float()\n",
                "tx = encoder(one_hot)\n",
                "# write tx to a binary file\n",
                "tx = tx.detach().numpy()\n",
                "with open(\"./file/tx.dat\", \"wb\") as f:\n",
                "    f.write(tx.tobytes())\n",
                "# run channel.py to generate rx\n",
                "os.system(\"python3 ./gnuradio/fading_awgn_model.py\")\n",
                "# read rx from a binary file\n",
                "with open(\"./file/rx.dat\", \"rb\") as f:\n",
                "    rx = np.frombuffer(f.read(), dtype=np.float32)\n",
                "rx = torch.from_numpy(rx).to(device)\n",
                "rx = rx.view(-1, 2)\n",
                "messages = messages[3:-5]\n",
                "\n",
                "# load the best decoder\n",
                "checkpoint = torch.load(CONFIG_TRAIN[\"best_decoder_path\"], map_location=device)\n",
                "decoder.load_state_dict(checkpoint[\"Decoder\"])\n",
                "\n",
                "# calculate the SER\n",
                "y_pred = decoder(rx)\n",
                "m_hat = torch.argmax(y_pred, -1)\n",
                "err = torch.sum(torch.not_equal(messages, m_hat)).to(\"cpu\").detach().numpy()\n",
                "SER = err / len(messages)\n",
                "print(\"SER: \", SER)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "torch",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.18"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
