{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Training from scratch\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD, Adam\n",
    "from keras.utils import to_categorical\n",
    "from scipy.special import erfc\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from utils import Encoder, Decoder, awgn\n",
    "from file_gen import *\n",
    "\n",
    "CONFIG_TRAIN = {\n",
    "    \"M\": 16,  # Number of constellation points\n",
    "    \"flag_train_model\": True,  # Flag to control training\n",
    "    \"training_snr\": 12,  # Training SNR (dB)\n",
    "    \"best_model_path\": \"./model/ae_simo_rayleigh_16qam_best_model.pth\",  # Path to save the best model\n",
    "    \"latest_checkpoint_path\": \"./model/ae_simo_rayleigh_16qam_latest_checkpoint.pth\",  # Path to save the latest checkpoint\n",
    "}\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "encoder = Encoder([CONFIG_TRAIN[\"M\"], 64, 64, 64, 2]).to(device)\n",
    "decoder = Decoder([8, 512, 512, 512, CONFIG_TRAIN[\"M\"]]).to(device)\n",
    "\n",
    "criterion = nn.NLLLoss()  # negative log likelihood loss\n",
    "best_loss = float(\"inf\")  # Initialize the best loss to infinity\n",
    "\n",
    "# Parameters\n",
    "sample_rate = 100e3  # Sample rate in Hz\n",
    "frequency = 10e3  # Frequency of the signal in Hz\n",
    "amplitude = 10000  # Amplitude of the signal\n",
    "\n",
    "if CONFIG_TRAIN[\"flag_train_model\"]:\n",
    "    # check if there is a checkpoint to resume training\n",
    "    if os.path.exists(CONFIG_TRAIN[\"latest_checkpoint_path\"]):\n",
    "        checkpoint = torch.load(\n",
    "            CONFIG_TRAIN[\"latest_checkpoint_path\"], map_location=device\n",
    "        )\n",
    "        # load the model, optimizer a loss history\n",
    "        encoder.load_state_dict(checkpoint[\"Encoder\"])\n",
    "        decoder.load_state_dict(checkpoint[\"Decoder\"])\n",
    "        parameters = list(encoder.parameters()) + list(decoder.parameters())\n",
    "        optimizer = Adam(parameters, lr=0.01)\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "        loss_hist = checkpoint[\"loss\"]\n",
    "        print(f\"Resuming training from epoch {len(loss_hist)}\")\n",
    "    else:  # start training from scratch\n",
    "        parameters = list(encoder.parameters()) + list(decoder.parameters())\n",
    "        optimizer = Adam(parameters, lr=0.01)\n",
    "        loss_hist = []\n",
    "        print(\"Training from scratch\")\n",
    "\n",
    "    tot_epochs = int(1e4)  # Total number of epochs to train\n",
    "    num_messages = int(1e4)  # Number of messages to use for training (batch size)\n",
    "else:\n",
    "    # check if there is a checkpoint to load the model\n",
    "    if os.path.exists(CONFIG_TRAIN[\"best_model_path\"]):\n",
    "        checkpoint = torch.load(CONFIG_TRAIN[\"best_model_path\"], map_location=device)\n",
    "        encoder.load_state_dict(checkpoint[\"Encoder\"])\n",
    "        decoder.load_state_dict(checkpoint[\"Decoder\"])\n",
    "        print(\"Model loaded. Training epoch: \", len(checkpoint[\"loss\"]))\n",
    "    else:\n",
    "        print(\n",
    "            \"Model not found, please set flag_train_model to True and train the model\"\n",
    "        )\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19984,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rx_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def ls_channel_estimation(tx, rx_samples):\n",
    "    # Detach the tensor from the computation graph\n",
    "    tx_detached = tx.detach().cpu().numpy()\n",
    "\n",
    "    # Compute the pseudo-inverse of X\n",
    "    X_inv = np.linalg.pinv(tx_detached)\n",
    "\n",
    "    # Compute the LS estimate of the channel response H\n",
    "    H = np.dot(X_inv, rx_samples)\n",
    "\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/yewentai/Codes/Auto-Encoder-in-MIMO-System/channel.py\", line 12, in <module>\n",
      "    from PyQt5 import Qt\n",
      "ModuleNotFoundError: No module named 'PyQt5'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (2,10000) and (19984,) not aligned: 10000 (dim 1) != 19984 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m     rx_samples \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(f\u001b[38;5;241m.\u001b[39mread(), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Perform LS channel estimation\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m H_ls \u001b[38;5;241m=\u001b[39m \u001b[43mls_channel_estimation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrx_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Combine H and rx\u001b[39;00m\n\u001b[1;32m     27\u001b[0m rx_csi \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m     28\u001b[0m     (\n\u001b[1;32m     29\u001b[0m         torch\u001b[38;5;241m.\u001b[39mtensor(rx_samples, device\u001b[38;5;241m=\u001b[39mdevice),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     33\u001b[0m )\n",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m, in \u001b[0;36mls_channel_estimation\u001b[0;34m(tx, rx_samples)\u001b[0m\n\u001b[1;32m      9\u001b[0m X_inv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mpinv(tx_detached)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Compute the LS estimate of the channel response H\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m H \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_inv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrx_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m H\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (2,10000) and (19984,) not aligned: 10000 (dim 1) != 19984 (dim 0)"
     ]
    }
   ],
   "source": [
    "messages = torch.randint(\n",
    "    0, CONFIG_TRAIN[\"M\"], size=(num_messages,), device=device\n",
    ")  # generate random messages\n",
    "one_hot = F.one_hot(messages, CONFIG_TRAIN[\"M\"]).float()  # convert to one hot encoding\n",
    "tx = encoder(one_hot)  # type of tx is torch.float32\n",
    "\n",
    "# Generate IQ samples from the transmitted signal\n",
    "I = tx[:, 0].cpu().detach().numpy()\n",
    "Q = tx[:, 1].cpu().detach().numpy()\n",
    "IQ_samples = np.stack((I, Q), axis=1)\n",
    "\n",
    "# Save to binary file\n",
    "with open(\"iq_samples.bin\", \"wb\") as f:\n",
    "    f.write(IQ_samples.tobytes())\n",
    "\n",
    "# Run GNURadio flowgraph to generate the received signal\n",
    "os.system(\"python3 channel.py\")\n",
    "\n",
    "# Read the received signal from the binary file\n",
    "with open(\"rx_samples.bin\", \"rb\") as f:\n",
    "    rx_samples = np.frombuffer(f.read(), dtype=np.float32)\n",
    "\n",
    "# Perform LS channel estimation\n",
    "H_ls = ls_channel_estimation(tx, rx_samples)\n",
    "\n",
    "# Combine H and rx\n",
    "rx_csi = torch.cat(\n",
    "    (\n",
    "        torch.tensor(rx_samples, device=device),\n",
    "        torch.tensor(H_ls, device=device),\n",
    "    ),\n",
    "    dim=1,\n",
    ")\n",
    "\n",
    "y_pred_ae = decoder(rx_csi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
